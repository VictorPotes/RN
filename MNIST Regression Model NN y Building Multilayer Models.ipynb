{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparación entre MNIST Regression Model NN y Building Multilayer Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrantes: Victor Potes y Ricardo Nuñez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este laboratorio es encontrar una optimización del modelo matemático, regresión lineal, donde para ello se busca optimizar su matriz de pesos “W” y el error “b”, a partir del resultado de cada uno de los algoritmos que se muestran a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo MNIST Regression Model NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo aprende ajustando los pesos (w) para reducir el error en el training set. Para ello busca el local óptimo para minimizar la función a través de gradientes, tal cuál lo muestra el siguiente segmento de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(cost, global_step):\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que solo maneja una capa debido a que sus entradas son procesadas una vez, generando las salidas finales en una iteración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x):\n",
    "    weight_init = tf.random_normal_initializer()\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    W = tf.get_variable(\"W\", [784, 10], initializer=weight_init)\n",
    "    b = tf.get_variable(\"b\", [10], initializer=bias_init)\n",
    "    output = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo Multilayer Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo Multilayer Regression Model utiliza un método que genera capas de la regresión lineal, a medida que se va optimizando. En otras palabras, las variables W y b se van optimizando en un modelo que utiliza varias capas, generando los cambios necesarios.\n",
    "\n",
    "En cada capa que se le va aplicando al modelo de la regresión lineal, se recibe una retroalimentación de la capa anterior a la actual para poder reajustar W y b. Estas capas se denominan como “capas escondidas” que operan un conjunto de variables de entrada y luego retornan un conjunto de variables de salida a sus capas consecutivas.\n",
    "\n",
    "En la implementación esto se puede visualizar en el código layer que es invocado por el método de inferencia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x):     \n",
    "    with tf.variable_scope(\"hidden_1\"):\n",
    "        hidden_1 = layer(x , [784, 256], [256])\n",
    "    with tf.variable_scope(\"hidden_2\"):\n",
    "        hidden_2 = layer(hidden_1, [256, 256], [256])\n",
    "    with tf.variable_scope(\"output\"):\n",
    "        output = layer(hidden_2, [256, 10], [10])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso podemos observar que se utilizan tres capas para optimizar el modelo de regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El uso de los algoritmos depende del trabajo a realizar, el número de clases que se requieran y el nivel de procesamiento de la máquina donde se va a ejecutar. Además el hecho que los pesos sean ajustados por cada capa por la que pasan, permite mejorar considerablemente la exactitud.\n",
    "\n",
    "Se puede observar que gracias a TensorFlow, podemos realizar redes neuronales de una manera más rápida y con pocas lineas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
